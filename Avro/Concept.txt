Overview: Flexible Avro serializer for .NET

Aims:
- should support schema-first, including generating C# types from a schema
- should support model-first, including generating a schema from C# types
- should support hybrid - mapping a schema to existing types


- map resolution should be flexible:
 - attribute support
 - naked type support for "obvious" models (constructor that matches all fields)
 - runtime (code only) configuration support
 - to work for both ctor-based and property/field-based assignment
 - optionally support constructor skipping and factory methods
 - support C# 6 primary constructors, including schema=>codegen (note: this should also support other layouts)


- should generate (whether IL or C#, not important) serializers that are tightly bound to a specific schema and types
- higher level abstraction should support multiple schemas against a single type model (backwards compatibility),
  including (where possible) processing previously unseen schemas (i.e. when doing loading a container / exchange, should be able
  to process new schemas)
- should allow "known past schemas" to be registered (perhaps via embedded resources?), so that they are not a surprise
- should allow pre-generation of serialization code / assembly, as a build step
- should support full container model, or more terse hash-prefix *only* model; in the case of hash-prefix only, a provider
  model should allow schema resolution, defaulting to "known past schemas"


- nulls: to be optionally supported
 - for reference-types, disabled by default, but if enabled, to be implemented via union with void (void as default)
 - for non-nullable value-types: n/a
 - for nullable value-types: implemented via union with void (void as default)


To explore:

- pooling:
 - some kinds of parent/child scope to allow re-use of resources withing a parent scope, such that each resource is only
   guaranteed for the duration of the child scope; for example, processing huge quantities of objects in a stream (the
   parent scope) - the data of each successive child object could be limited to that iteration (item); ideas:
    - char/blob data could be re-using a shared pool of char/byte-buffers, exposed via something that presents
	  TextReader/TextWriter (char) or Stream (blob) APIs, presumably wrapping 0-* ArraySegment instances
    - DTO objects themselves could be pooled and reclaimed/reset/reused to avoid allocations (unless we
	  are demanding ctor-based assignment)

Questions:

- is it reasonable to over-read the input? meaning: can we assume that a stream (when not reading sub-objects etc) is
  terminated (framed) to a single object? If so, we can use a local read-buffer; if not, we can't - as reading a varint
  has to be done byte-by-byte if we aren't allowed to over-read